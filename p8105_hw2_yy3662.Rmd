---
title: "p8105_hw2_yy3662"
author: "Yunyi Yang"
date: "2025-09-29"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1

```{r}
library(tidyverse)
library(skimr)
p1task1 <- read.csv(file = "./Data/fivethirtyeight_datasets/pols-month.csv",
                  ,na = c(".", "NA", "")) |>
  separate(mon, c("year", "month", "day"), convert = TRUE) |>
  mutate(month = month.name[month]) |>
  mutate(president = case_match(prez_dem, 1 ~ "dem", 0 ~ "gop")) |>
  select(-day, -prez_dem, -prez_gop)



p1task2 <- read.csv(file = "./Data/fivethirtyeight_datasets/snp.csv",
                  ,na = c(".", "NA", ""))
p1task2$date <- as.Date(p1task2$date, "%m/%d/%y")
p1task2$date <-as.character(p1task2$date)
p1task2 <- separate(p1task2, date, c("year", "month", "day"), convert = TRUE) |>
  mutate(p1task2, month = month.name[month]) |>
  select(-date, -day) # I find date is unnecessary in final dataset
p1task2$year[which(p1task2$year > 2025)] <- p1task2$year[which(p1task2$year > 2025)] - 100L
# because some dates are incorrect because of basic logic of as.Date, so we convert some years like 2065 back to 1965.


p1task3 <- read.csv(file = "./Data/fivethirtyeight_datasets/unemployment.csv",
                  ,na = c(".", "NA", "")) |>
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment") |>
  mutate(month = month.name[match(tolower(month), tolower(month.abb))]) |>
  rename(year = "Year")

join1 <- left_join(p1task1, p1task2, by = c("year", "month"))

join2 <- left_join(join1, p1task3, by = c("year", "month"))
skimr::skim(join2)
summary(join2)
```

pols-month which names p1task1 contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time:
mon: date of the count
prez_gop: indicator of whether the president was republican on the associated date (1 = yes, 0 = no)
gov_gop: the number of republican governors on the associated date
sen_gop: the number of republican senators on the associated date
rep_gop: the number of republican representatives on the associated date
prez_dem: indicator of whether the president was democratic on the associated date (1 = yes, 0 = no)
gov_dem: the number of democratic governors on the associated date
sen_dem: the number of democratic senators on the associated date
rep_dem: the number of democratic representatives on the associated date

snp which names p1task2 contains 787 observations of 2 variables related to Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole:
date: the date of the observation
close: the closing values of the S&P stock index on the associated date

unemployment which names p1task3 contains 3 variables:
year: year of measurement
month: month of measurement
unemployment: the percentage of unemployment of specific year and month

In our final dataset, we have 822 observations and 11 variables, where contains year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, presidents shows which party is president from at that year, close, unemployment. The year range is from 1947-01 to 2015-06.

# Problem 2
```{r}
library(readxl)
mrtrash <- read_excel("./Data/202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N709")
mrtrash <- janitor::clean_names(mrtrash) |>
  mutate(mrtrash$name, name = "mrtrash")
mrtrash$sports_balls <- as.integer(round(mrtrash$sports_balls))

professor <- read_excel("./Data/202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M134")
professor <- janitor::clean_names(professor) |>
  mutate(professor$name, name = "professor")

Gwynnda <- read_excel("./Data/202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L351")
Gwynnda <- janitor::clean_names(Gwynnda) |>
  mutate(Gwynnda$name, name = "Gwynnda")

mrtrash$year <- as.numeric(mrtrash$year) #mrtrash's year variable is not numeric as professor and Gwynnda
join3 <- bind_rows(mrtrash, professor, Gwynnda)
skimr::skim(join3)
summary(join3)

sum(filter(join3, name == "professor")$weight_tons)
sum(filter(join3, name == "Gwynnda", year == "2022", month == "June")$cigarette_butts)
```
Our final dataset has 1188 observations and 15 variables, which includes "dumpster" series number, "month", "year" and "date" that the dumpster was collected, and "weight_tons" which means total weights of trash in the dumpster, "volumn_cubic_yards" which means volumn in cubic yards, and amount of different trash includes: "plastic_bottles", "polystyrene", cigarette_butts", "glass_bottles", "plastic_bags", "wrappers", "sports_balls", and "homes_powered" describes how many homes are powered by these energy from trash, and "name" indicates which trash wheel collected these trash. 
The total weight of Mr. Trash Wheel is 282.26 tons, and total number of cigarettes butts in 2022.6 from Gwynnda is 18120.

# Problem 3
```{r}
zipcode <- read_csv(file = "./Data/zillow_data/Zip Codes.csv",
                  ,na = c(".", "NA", ""))
zillow <- read_csv(file = "./Data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
                  ,na = c(".", "NA", ""))
skimr::skim(zipcode)
skimr::skim(zillow)
filter(zillow, )
zipcode <- janitor::clean_names(zipcode)

zillow <- janitor::clean_names(zillow) |>
  rename(zip_code = "region_name")

duplicate <- filter(janitor::get_dupes(zipcode, zip_code), county == "New York") |>
  select(-dupe_count)
zipcode <- anti_join(zipcode, duplicate, by = names(duplicate)) #delete two duplicated rows which have same zipcode but different county.

join4 <- left_join(zillow, zipcode, by = "zip_code") |>
  select(-file_date) #delete some useless variables

not_included_zip <- anti_join(zipcode, zillow, by = "zip_code") #make a dataframe which includes zipcodes not included in zillow
skim(zipcode)
skim(not_included_zip)

nrow(not_included_zip)


final_join4 <- pivot_longer(join4, 
    x2015_01_31:x2024_08_31,
    names_to = "time",
    values_to = "zillow_val"
)
final_join4 <- drop_na(final_join4, zillow_val) #In final dataset, we keep the NA neighborhood, remove the NA zillow value to remove some useless time point.

length(unique(na.omit(final_join4$neighborhood))) #ignore NA neighborhood when calculate how many different neighborhood
```
In our final dataset, we have 10450 observations depends on the date we observe, because we have too many missing data in many dates for one zipcode, so I just treat different dates as a variable to make this final dataset easier to be read. It includes 149 different zipcodes which is same as number of rows of zillow. There are 42 different neighborhood.

By analyzing the not_included_zip, the zipcode mainly from county code 05, 41, 61, 81 are not included in the zillow dataset. I think there are two possible reasons: 

First, by analyzing the not_included_zip, I found there are 137 missing values of neighborhood in Zipcodes not included in the zillow dataset, and there are totally 142 missing values of neighborhood in zipcode dataset. Because of that, I think maybe zillow dropped these zipcodes because of the incomplete of data.

Second, thew county code of these zipcodes are mainly gathering around 05, 41, 61, 81, so it is possible that zillow didn't have enough people to collect data in these areas in New York.

```{r}
diff_table <- tibble(diff = join4$x2020_01_31 - join4$x2021_01_31, zipcode = join4$zip_code, county_name = join4$county_name, neighborhood = join4$neighborhood) |>
  drop_na() |>
  arrange(desc(diff))
top10 <- diff_table[1:10,]
top10
```
Based on the top10 housing decreasing prices table, the lower manhattan, lower east side had the worst decreasing of housing price. It may caused by the disease distribution in New York, the place had more patients may got a worse housing price.